{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5653497",
   "metadata": {},
   "source": [
    "# PyTorch 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b13b7",
   "metadata": {},
   "source": [
    "<img src=\"pytorch2 - 1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913b7ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6060c3c",
   "metadata": {},
   "source": [
    "## Quick code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e5350b",
   "metadata": {},
   "source": [
    "### Before PyTorch 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7c3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb8bbf",
   "metadata": {},
   "source": [
    "### After PyTorch 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a1808f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Windows not yet supported for torch.compile",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mresnet50()   \n\u001b[1;32m----> 5\u001b[0m compiled_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\myenv\\lib\\site-packages\\torch\\__init__.py:1441\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1440\u001b[0m     backend \u001b[38;5;241m=\u001b[39m _TorchCompileInductorWrapper(mode, options, dynamic)\n\u001b[1;32m-> 1441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnopython\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfullgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m)\u001b[49m(model)\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:413\u001b[0m, in \u001b[0;36moptimize\u001b[1;34m(backend, nopython, guard_export_fn, guard_fail_fn, disable, dynamic)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    381\u001b[0m     backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m     dynamic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    388\u001b[0m ):\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    The main entrypoint of TorchDynamo.  Do graph capture and call\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    backend() to optimize extracted graphs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;124;03m            ...\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m     \u001b[43mcheck_if_dynamo_supported\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;66;03m# Note: The hooks object could be global instead of passed around, *however* that would make\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;66;03m# for a confusing API usage and plumbing story wherein we nest multiple .optimize calls.\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# There is some prior art around this, w/r/t nesting backend calls are enforced to be the same\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;66;03m# compiler, however, this feels onerous for callback and hooks, and it feels better to give our users an\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;66;03m# easier to understand UX at the cost of a little more plumbing on our end.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     hooks \u001b[38;5;241m=\u001b[39m Hooks(guard_export_fn\u001b[38;5;241m=\u001b[39mguard_export_fn, guard_fail_fn\u001b[38;5;241m=\u001b[39mguard_fail_fn)\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:375\u001b[0m, in \u001b[0;36mcheck_if_dynamo_supported\u001b[1;34m()\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_if_dynamo_supported\u001b[39m():\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 375\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows not yet supported for torch.compile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython 3.11+ not yet supported for torch.compile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Windows not yet supported for torch.compile"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50()   \n",
    "compiled_model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c8802",
   "metadata": {},
   "source": [
    "## 1. Getting Started\n",
    "\n",
    "Why get GPU info?\n",
    "\n",
    "PyTorch 2.0 features work best on newer NVIDIA GPUs.\n",
    "\n",
    "To find our if your GPU is compatible, see NVIDIA GPU compatibility score -  https://developer.nvidia.com/cuda-gpus\n",
    "\n",
    "If your GPU has score of 8.0+ , it can leverage most or all of new PyTorch 2.0 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2858003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: NVIDIA_GeForce_RTX_4090\n",
      "GPU capability score: (8, 9)\n",
      "GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\n",
      "GPU information:\n",
      "Wed May 31 11:17:05 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.98                 Driver Version: 535.98       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090      WDDM  | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   42C    P8              20W / 450W |    647MiB / 24564MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090      WDDM  | 00000000:05:00.0 Off |                  Off |\n",
      "|  0%   38C    P8               6W / 450W |      0MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1504    C+G   ...Brave-Browser\\Application\\brave.exe    N/A      |\n",
      "|    0   N/A  N/A      1684    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7460    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8396    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9112    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      9496    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A     10820    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13772    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using a NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find(\"failed\") >= 0:\n",
    "    print(\"Not connected to a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")\n",
    "\n",
    "  # Get GPU name\n",
    "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "  gpu_name = gpu_name[1]\n",
    "  GPU_NAME = gpu_name.replace(\" \", \"_\") # remove underscores for easier saving\n",
    "  print(f'GPU name: {GPU_NAME}')\n",
    "\n",
    "  # Get GPU capability score\n",
    "  GPU_SCORE = torch.cuda.get_device_capability()\n",
    "  print(f\"GPU capability score: {GPU_SCORE}\")\n",
    "  if GPU_SCORE >= (8, 0):\n",
    "    print(f\"GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\")\n",
    "  else:\n",
    "    print(f\"GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\")\n",
    "  \n",
    "  # Print GPU info\n",
    "  print(f\"GPU information:\\n{gpu_info}\")\n",
    "\n",
    "else:\n",
    "  print(\"PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498644e",
   "metadata": {},
   "source": [
    "### 1.1 Globally set devices\n",
    "\n",
    "Previously we've set device of our tensor/model using `.to(device)`\n",
    "\n",
    "But in PyTorch 2.0, it is possible to set the device with context manager as well as a global device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c396a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights are on devie: cuda:0\n",
      "Layer creating data on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set the device with context manager (PyTorch 2.x+)\n",
    "with torch.device(\"cuda\"):\n",
    "    # All tensors or PyTorch objects created in the context manager will be on target device\n",
    "    layer = torch.nn.Linear(20,30)\n",
    "    print(f\"Layer weights are on devie: {layer.weight.device}\")\n",
    "    print(f\"Layer creating data on device: {layer(torch.randn(120,20)).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad7d52ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights are on devie: cuda:0\n",
      "Layer creating data on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device globally\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "layer = torch.nn.Linear(20,30)\n",
    "print(f\"Layer weights are on devie: {layer.weight.device}\")\n",
    "print(f\"Layer creating data on device: {layer(torch.randn(120,20)).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f565c50",
   "metadata": {},
   "source": [
    "## 2. Setting up the experiments\n",
    "\n",
    "Time to test speed!\n",
    "\n",
    "TO keep things simple, we will run 4 experiments.\n",
    "\n",
    "* Model: ResNet 50\n",
    "* Data: Cifar10\n",
    "* Epochs: 5(single run) and 3x5(multi run)\n",
    "* Batch Size: 128\n",
    "* Image: 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cb167f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0\n",
      "TorchVision version: 0.15.0\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TorchVision version: {torchvision.__version__}\")\n",
    "\n",
    "# Set the target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dcee17",
   "metadata": {},
   "source": [
    "<img src=\"pytorch2 - 2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68568548",
   "metadata": {},
   "source": [
    "### 2.1 Create model and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe31471e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[232]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model weights and transforms\n",
    "model_weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "tranforms = model_weights.transforms()\n",
    "\n",
    "tranforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff548c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\HIMANSHU GOSWAMI/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 97.8M/97.8M [00:05<00:00, 19.2MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "model = torchvision.models.resnet50(weights=model_weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48a2c151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of parameters in the model\n",
    "\n",
    "total_params = sum(torch.numel(param) for param in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df87d5",
   "metadata": {},
   "source": [
    "**Note:** PyTorch 2.0 *relative* speedups will be most noticable when as much of the GPU as possble is being used.\n",
    "    This means a larger model may take longer to train on the whole but will relatively faster.\n",
    "    \n",
    "    Eg. a model with 1M parameters may take ~10 minutes to train but model with 25M parameters may take ~20 minutes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19cf463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[232]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model(num_classes=10):\n",
    "    \"\"\"\n",
    "    Create  a resnet50 model with transform and returns them both.\n",
    "    \"\"\"\n",
    "    model_weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "    transforms = model_weights.transforms()\n",
    "    model = torchvision.models.resnet50(weights=model_weights)\n",
    "    \n",
    "    # Adjust the head layer\n",
    "    model.fc = torch.nn.Linear(in_features=2048,\n",
    "                              out_features=num_classes)\n",
    "    \n",
    "    return model, transforms\n",
    "\n",
    "model, transforms = create_model()\n",
    "\n",
    "transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e053c4",
   "metadata": {},
   "source": [
    "### 2.2 Speedups are most noticable when a large portion of GPU is being used\n",
    "\n",
    "Since modern GPUs are so *fast* at performing operations, you will often notice the majority of *relative* speedups when as much data as possible is on the GPU.\n",
    "\n",
    "In practice, you generally want to use as much of your GPU memory as possible.\n",
    "\n",
    "* Increasing the batch size.\n",
    "* Increasing data size - 224,224  instead of 32,32\n",
    "* Increase the model size - for example instead of using model with 1M parameters, use a model with 10M parameters.\n",
    "* Decrease data transfer - since bandwidth costs (CPU <=> GPU) will slow down a GPU\n",
    "\n",
    "As a result of doing the above, your relative speedups should be better.\n",
    "\n",
    "Eg. overall training time may take longer but not linearly.\n",
    "\n",
    "Resource for improving model speed = https://sebastianraschka.com/blog/2023/pytorch-faster.html\n",
    "\n",
    "**Note:** This concept of using as much data on GPU as possible isn't restricted specifically to PyTorch 2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72459df4",
   "metadata": {},
   "source": [
    "### 2.3 Checking the memory limits of our GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59f66ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total free GPU Memory: 22.926 GB\n",
      "Total GPU Memory: 25.757 GB\n"
     ]
    }
   ],
   "source": [
    "# Check available GPU memory and total GPU memory\n",
    "total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info()\n",
    "print(f\"Total free GPU Memory: {round(total_free_gpu_memory * 1e-9, 3)} GB\")\n",
    "print(f\"Total GPU Memory: {round(total_gpu_memory * 1e-9, 3)} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d8eda",
   "metadata": {},
   "source": [
    "* If the GPU has 16GB+ of free memory, set batch size to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea8f750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory available is 22.926 GB, using batch size of 128 and image size 224\n"
     ]
    }
   ],
   "source": [
    "# Set batch size depending on amount of GPU memory\n",
    "total_free_gpu_memory_gb = round(total_free_gpu_memory * 1e-9, 3)\n",
    "if total_free_gpu_memory_gb >= 16:\n",
    "    BATCH_SIZE = 128 # Note: you could experiment with higher values here if you like.\n",
    "    IMAGE_SIZE = 224\n",
    "    print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
    "else:\n",
    "    BATCH_SIZE = 32\n",
    "    IMAGE_SIZE = 128\n",
    "    print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3784a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data transforms:\n",
      "ImageClassification(\n",
      "    crop_size=224\n",
      "    resize_size=224\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transforms.crop_size = IMAGE_SIZE\n",
    "transforms.resize_size = IMAGE_SIZE \n",
    "print(f\"Updated data transforms:\\n{transforms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbcc25c",
   "metadata": {},
   "source": [
    "### 2.4 More potential speedups with TF32\n",
    "\n",
    "TF32 = TensorFloat32\n",
    "\n",
    "TensorFloat32 = a datatype that bridges Float32 and Float16\n",
    "\n",
    "What we want in computing:\n",
    "1. Fast model training\n",
    "2. Accurate model training\n",
    "\n",
    "TensorFloat32 = a datatype from NVIDIA which combines float32 and float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08c3fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU with score: (8, 9), enabling TensorFloat32 (TF32) computing (faster on new GPUs)\n"
     ]
    }
   ],
   "source": [
    "if GPU_SCORE >= (8, 0):\n",
    "    print(f\"[INFO] Using GPU with score: {GPU_SCORE}, enabling TensorFloat32 (TF32) computing (faster on new GPUs)\")\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "else:\n",
    "    print(f\"[INFO] Using GPU with score: {GPU_SCORE}, TensorFloat32 (TF32) not available, to use it you need a GPU with score >= (8, 0)\")\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43da2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da04ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee4d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09360c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
